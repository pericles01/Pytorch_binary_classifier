04.01.23 11:57:33 INFO: Setup Dataset
04.01.23 11:57:33 INFO: Successfully loaded dataset
Binary_Classifier(
  (block1): Sequential(
    (0): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.25, inplace=False)
  )
  (block2): Sequential(
    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.25, inplace=False)
  )
  (block3): Sequential(
    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.25, inplace=False)
  )
  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (firstlayer): Linear(in_features=576, out_features=16, bias=True)
  (lastlayer): Linear(in_features=16, out_features=1, bias=True)
)
04.01.23 11:57:33 INFO: Starting training...
Train Epoch: 0 [0/6633 (0%)]    Loss: 0.687760
Train Epoch: 0 [1600/6633 (24%)]        Loss: 0.439739
Train Epoch: 0 [3200/6633 (48%)]        Loss: 0.386948
Train Epoch: 0 [4800/6633 (72%)]        Loss: 0.200930
Train Epoch: 0 [6400/6633 (96%)]        Loss: 0.422743
Train Epoch: 0
Train set: Average loss: 1.0083, Accuracy: 2875.0/6633 (43%)

Val Epoch: 0
Validation set: Average loss: 0.1171, Accuracy: 262/715 (37%)

Train Epoch: 1 [0/6633 (0%)]    Loss: 0.270764
Train Epoch: 1 [1600/6633 (24%)]        Loss: 0.209479
Train Epoch: 1 [3200/6633 (48%)]        Loss: 0.565882
Train Epoch: 1 [4800/6633 (72%)]        Loss: 0.181628
Train Epoch: 1 [6400/6633 (96%)]        Loss: 0.098723
Train Epoch: 1
Train set: Average loss: 0.9776, Accuracy: 2875.0/6633 (43%)

Val Epoch: 1
Validation set: Average loss: 0.0826, Accuracy: 262/715 (37%)

Train Epoch: 2 [0/6633 (0%)]    Loss: 0.105845
Train Epoch: 2 [1600/6633 (24%)]        Loss: 0.471555
Train Epoch: 2 [3200/6633 (48%)]        Loss: 0.247445
Train Epoch: 2 [4800/6633 (72%)]        Loss: 0.105878
Train Epoch: 2 [6400/6633 (96%)]        Loss: 0.032610
Train Epoch: 2
Train set: Average loss: 0.8165, Accuracy: 2875.0/6633 (43%)

Val Epoch: 2
Validation set: Average loss: 0.2135, Accuracy: 262/715 (37%)

Train Epoch: 3 [0/6633 (0%)]    Loss: 0.417545
Train Epoch: 3 [1600/6633 (24%)]        Loss: 0.054412
Train Epoch: 3 [3200/6633 (48%)]        Loss: 0.082649
Train Epoch: 3 [4800/6633 (72%)]        Loss: 0.066954
Train Epoch: 3 [6400/6633 (96%)]        Loss: 0.237697
Train Epoch: 3
Train set: Average loss: 1.4614, Accuracy: 2875.0/6633 (43%)

Val Epoch: 3
Validation set: Average loss: 0.1720, Accuracy: 262/715 (37%)

Train Epoch: 4 [0/6633 (0%)]    Loss: 0.100348
Train Epoch: 4 [1600/6633 (24%)]        Loss: 0.379678
Train Epoch: 4 [3200/6633 (48%)]        Loss: 0.178339
Train Epoch: 4 [4800/6633 (72%)]        Loss: 0.116744
Train Epoch: 4 [6400/6633 (96%)]        Loss: 0.061132
Train Epoch: 4
Train set: Average loss: 0.0000, Accuracy: 2875.0/6633 (43%)

Val Epoch: 4
Validation set: Average loss: 0.0246, Accuracy: 262/715 (37%)

04.01.23 12:00:56 INFO: End of Training
train_loss: [0.41365804514701826, 0.30559932919645527, 0.2678871782305819, 0.2303663118719965, 0.20802903469226125], lenght: 5
val_loss: [tensor(43.3439), 0.2504062237838904, tensor(43.3439), 0.21255088115317955, tensor(43.3439), 0.18830323607350388, tensor(43.3439), 0.16350023671984673, tensor(43.3439), 0.16896687333032281], lenght: 10
train_acc: [], lenght: 0
val_acc: [tensor(36.6434), tensor(36.6434), tensor(36.6434), tensor(36.6434), tensor(36.6434)], lenght: 5

04.01.23 12:00:56 INFO: training duration: -1:-1:60.00
y_pred: [[1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], lenght: 163
y_true: [[1, 1, 0, 1, 1, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1, 1, 0], [0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 0], [1, 1, 1, 0, 0, 1, 1, 1], [1, 0, 1, 1, 0, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 0], [0, 0, 0, 1, 1, 1, 0, 1], [1, 0, 1, 0, 1, 1, 1, 0], [1, 0, 0, 1, 0, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 1, 1, 0, 1, 1], [1, 1, 1, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 0, 1], [0, 1, 1, 0, 1, 1, 0, 1], [1, 1, 1, 1, 0, 1, 1, 0], [0, 0, 0, 0, 1, 1, 1, 0], [1, 0, 1, 1, 0, 1, 1, 0], [1, 1, 1, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 0, 0, 1, 1], [1, 0, 0, 1, 1, 0, 1, 0], [0, 1, 0, 1, 0, 0, 1, 0], [0, 1, 0, 1, 1, 0, 1, 0], [0, 1, 0, 0, 0, 1, 0, 1], [1, 0, 1, 1, 0, 1, 1, 0], [1, 1, 1, 1, 0, 1, 0, 1], [0, 1, 1, 1, 0, 0, 0, 0], [0, 1, 0, 1, 1, 0, 1, 1], [1, 1, 0, 0, 1, 1, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 1], [1, 0, 1, 0, 0, 1, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1], [0, 0, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 1, 0], [1, 0, 0, 1, 1, 1, 0, 1], [1, 1, 0, 0, 1, 1, 0, 0], [1, 1, 0, 0, 0, 1, 1, 1], [0, 0, 1, 0, 1, 1, 1, 1], [0, 0, 1, 0, 1, 1, 1, 0], [1, 0, 0, 1, 1, 0, 0, 1], [0, 0, 1, 1, 1, 1, 0, 0], [0, 1, 1, 1, 0, 1, 1, 1], [1, 0, 1, 0, 1, 1, 0, 0], [1, 1, 1, 1, 0, 0, 1, 0], [1, 1, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 0, 1, 0, 0], [0, 1, 1, 1, 1, 0, 1, 1], [1, 1, 1, 0, 1, 0, 1, 1], [1, 0, 0, 0, 1, 1, 1, 1], [1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 1, 0, 1, 1, 0, 1], [1, 0, 1, 1, 1, 1, 0, 0], [0, 0, 1, 1, 1, 0, 0, 1], [0, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 0, 0, 1, 1], [1, 0, 1, 0, 1, 0, 0, 1], [1, 1, 0, 0, 0, 0, 1, 0], [1, 0, 1, 1, 0, 1, 1, 0], [0, 1, 1, 0, 1, 0, 1, 0], [1, 1, 1, 0, 1, 1, 1, 0], [0, 0, 0, 1, 1, 1, 1, 0], [1, 0, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 0, 0, 1, 1, 0], [0, 1, 0, 0, 1, 0, 1, 1], [1, 1, 0, 1, 0, 0, 1, 1], [1, 0, 1, 1, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 1, 1, 1, 1, 0, 0], [1, 1, 1, 0, 1, 1, 0, 1], [0, 1, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 0, 1, 1, 0], [1, 1, 0, 1, 1, 0, 0, 0], [0, 1, 0, 0, 0, 1, 1, 0], [1, 0, 1, 1, 0, 0, 0, 1], [1, 0, 0, 1, 1, 1, 0, 0], [1, 1, 0, 0, 0, 1, 0, 1], [0, 1, 1, 1, 1, 1, 0, 1], [1, 0, 1, 1, 0, 1, 0, 1], [1, 1, 1, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 1, 1], [0, 0, 0, 1, 1, 0, 0, 1], [1, 1, 1, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 0, 1, 1], [1, 0, 0, 1, 1, 0, 0, 1], [1, 1, 0, 0, 0, 1, 0, 1], [1, 0, 1, 1, 1, 0, 1, 0], [1, 1, 0, 0, 0, 0, 1, 0], [1, 0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1], [1, 0, 0, 1, 0, 0, 0, 1], [1, 1, 0, 1, 0, 0, 1, 1], [0, 1, 1, 0, 1, 0, 0, 0], [0, 1, 1, 1, 1, 0, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 0, 0, 1, 1, 0], [0, 1, 0, 0, 1, 1, 1, 1], [0, 1, 0, 1, 1, 1, 1, 1], [0, 1, 1, 0, 0, 1, 0, 1], [1, 1, 0, 0, 1, 0, 1, 1], [1, 1, 1, 1, 1, 0, 1, 1], [0, 1, 0, 1, 1, 1, 0, 0], [0, 1, 1, 1, 1, 1, 0, 0], [1, 1, 0, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 1], [0, 1, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 0, 1, 1, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1], [1, 0, 1, 0, 1, 1, 0, 0], [1, 0, 0, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 1, 1], [0, 0, 1, 1, 0, 1, 1, 1], [1, 0, 1, 1, 0, 1, 1, 1], [1, 0, 1, 0, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 1, 0, 0, 1, 1, 1], [1, 0, 0, 0, 0, 0, 0, 1], [1, 1, 1, 1, 1, 0, 0, 0], [1, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 0, 1, 1], [1, 1, 1, 0, 0, 0, 1, 1], [1, 0, 0, 0, 1, 1, 1, 1], [1, 1, 0, 1, 1, 0, 1, 1], [0, 0, 1, 0, 0, 1, 0, 1], [1, 1, 1, 0, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 0, 0, 1, 0, 1, 0], [1, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 1, 0, 0, 1, 0], [1, 1, 1, 0, 1, 0, 1, 1], [1, 1, 0, 0, 1, 1, 0, 1], [1, 0, 0, 0, 0, 0, 1, 1], [0, 1, 1, 1, 1, 1, 1, 0], [0, 1, 0, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 1, 1, 0], [0, 0, 1, 0, 0, 1, 1, 1], [1, 0, 0, 1, 1, 0, 1, 0], [1, 0, 0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 1], [0, 1, 1, 0, 1, 0, 1, 1], [1, 0, 0, 1, 0, 0, 0, 0], [1, 0, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0], [0, 1, 0, 0, 0, 1, 1, 1], [1, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 1]], lenght: 163
Traceback (most recent call last):
  File "C:\Users\junio\OneDrive\Desktop\Studium\Neuronale Nezte\Hausarbeit\main.py", line 183, in <module>
    cf_matrix = confusion_matrix(y_true, y_pred)
  File "C:\Users\junio\anaconda3\envs\TorchEnv\lib\site-packages\sklearn\metrics\_classification.py", line 307, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\junio\anaconda3\envs\TorchEnv\lib\site-packages\sklearn\metrics\_classification.py", line 85, in _check_targets
    type_true = type_of_target(y_true)
  File "C:\Users\junio\anaconda3\envs\TorchEnv\lib\site-packages\sklearn\utils\multiclass.py", line 299, in type_of_target
    raise ValueError(
ValueError: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.